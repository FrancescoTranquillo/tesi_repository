plot(summary(compare,metric = "Sens"))
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3))
# bwplot(compare,metric="Accuracy")
plot(summary(compare,metric = "Sens"))
# bwplot(compare,metric="Accuracy")
plot(summary(compare,metric = "Sens"))
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3))
# bwplot(compare,metric="Accuracy")
plot(summary(compare,metric = "Sens"))
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod0, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# bwplot(compare,metric="Accuracy")
plot(summary(compare))
# bwplot(compare,metric="Accuracy")
plot(summary(compare,metric = "Sens"))
summary(compare,metric = "Sens")
splom(compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
dotplot(compare, scales=scales)
densityplot(compare, scales=scales, pch = "|",)
densityplot(compare, scales=scales, pch = "*")
xyplot(compare, models=c("SVM.Linear", "NN"))
parallelplot(compare)
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod1, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod2, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod3, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod3, testing)
parallelplot(compare,metric = "Rsquared")
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3))
splom(compare)
parallelplot(compare,metric = "Rsquared")
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2))
parallelplot(compare,metric = "Rsquared")
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1))
parallelplot(compare,metric = "Rsquared")
bwplot(compare, scales=scales)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3))
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
summary(compare,metric = "Sens")
# bwplot(compare,metric="Accuracy")
plot(summary(compare)
)
# bwplot(compare,metric="Accuracy")
summary(compare)
mod4 <- train(TARGET ~ ., data = training,
method = "Bayesglm",
trControl = fitControl)
mod4 <- train(TARGET ~ ., data = training,
method = "bayesglm",
trControl = fitControl)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4))
# bwplot(compare,metric="Accuracy")
summary(compare)
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod4, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
fitControl <- trainControl(method = "repeatedcv",
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
verboseIter=T,allowParallel = T)
svmGrid <-  expand.grid(size=seq(1, 5,1),
decay=seq(0.1,1,0.1))
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
verboseIter=T,allowParallel = T)
svmGrid <-  expand.grid(size=seq(1, 5,1),
decay=seq(0.1,1,0.1))
mod0 <- train(TARGET ~ ., data = training,
method = "nnet",
# tuneGrid = svmGrid,
trControl = fitControl)
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod4, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
mod1 <- train(TARGET ~ ., data = training,
method = "svmLinear",
trControl = fitControl)
mod3 <- train(TARGET ~ ., data = training,
method = "glm",
trControl = fitControl)
mod2 <- train(TARGET ~ ., data = training,
method = "svmRadial",
trControl = fitControl)
mod4 <- train(TARGET ~ ., data = training,
method = "bayesglm",
trControl = fitControl)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4))
# bwplot(compare,metric="Accuracy")
summary(compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
plot(mod3)
plot(mod4)
plot(mod2)
plot(mod1)
plot(mod3)
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod4, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod3, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod2, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod1, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
splom(compare)
parallelplot(compare,metric = "Rsquared")
parallelplot(compare)
xyplot(compare, models=c("SVM.Linear", "NN"))
dotplot(compare, scales=scales)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
verboseIter=T,allowParallel = T,
summaryFunction = twoClassSummary)
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
verboseIter=T,allowParallel = T,
summaryFunction = twoClassSummary)
# sampling = "smote")
#
# svmGrid <-  expand.grid(size=seq(1, 5,1),
#                         decay=seq(0.1,1,0.1))
mod0 <- train(TARGET ~ ., data = training,
method = "nnet",
# tuneGrid = svmGrid,
trControl = fitControl)
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod1, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
mod2 <- train(TARGET ~ ., data = training,
method = "svmRadial",
trControl = fitControl)
mod3 <- train(TARGET ~ ., data = training,
method = "glm",
trControl = fitControl)
mod4 <- train(TARGET ~ ., data = training,
method = "bayesglm",
trControl = fitControl)
mod5 <- train(TARGET ~ ., data = training,
method = "knn",
trControl = fitControl)
mod6 <- train(TARGET ~ ., data = training,
method = "rda",
trControl = fitControl)
mod5 <- train(TARGET ~ ., data = training,
method = "knn",
trControl = fitControl)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4,
K.NN=mod5 ))
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4,
K.NN=mod5 ))
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4))
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod1, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod2, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
mod2 <- train(TARGET ~ ., data = training,
method = "knn",
trControl = fitControl)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
K.NN=mod2,
LogReg=mod3,
BayesLogReg=mod4))
mod2
plot(mod2)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
LogReg=mod3,
BayesLogReg=mod4))
SVM.Linear=mod1)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1))
# bwplot(compare,metric="Accuracy")
summary(compare)
splom(compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
mod3 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "glm",
trControl = fitControl)
# saveRDS(mod0, "model0.rds")
# my_model <- readRDS(here("model.rds"))
predictions <- predict(mod3, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
mod3
mod3$pred
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 2,
classProbs = TRUE,
verboseIter=T,allowParallel = T,
summaryFunction = twoClassSummary,
savePredictions = T)
# sampling = "smote")
#
# svmGrid <-  expand.grid(size=seq(1, 5,1),
#                         decay=seq(0.1,1,0.1))
mod0 <- train(TARGET ~ ., data = training,
method = "nnet",
# tuneGrid = svmGrid,
trControl = fitControl)
mod0
predictions <- predict(mod0, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
selectedIndices <- mod0$pred$decay==0.1
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=M, d=factor(obs, levels = c("R", "M")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
library(ggplo2)
library(ggplot2)
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=M, d=factor(obs, levels = c("R", "M")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
library(plotROC)
installed.packages("plotROC")
install.packages("plotROC")
library(plotROC)
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=M, d=factor(obs, levels = c("R", "M")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=TARGET, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
mod0$pred
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pos, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pos, d=factor(obs, levels = c("pos", "neg")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
plot(mod0)
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=size, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
plot(roc(predictor = mod0$pred$pos, response = mod0$pred$obs))
install.packages("pROC")
library(pROC)
plot(roc(predictor = mod0$pred$pos, response = mod0$pred$obs))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pos, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
selectedIndices <- mod0$pred$size==5
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pos, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pred, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=posd, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pos, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
plot(roc(predictor = mod0$pred$pos, response = mod0$pred$obs))
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
# bwplot(compare,metric="Accuracy")
summary(compare)
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=mod0, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=M, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pos, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
g <- ggplot(mod0$pred[selectedIndices, ], aes(m=pred, d=factor(obs, levels = c("1", "0")))) +
geom_roc(n.cuts=0) +
coord_equal() +
style_roc()
g + annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g)))))
plot(roc(predictor = mod0$pred$pos, response = mod0$pred$obs))
plot(roc(predictor = mod0$pred$pos, response = mod0$pred$obs))
table(testing$TARGET)
testing[which(testing$TARGET=="pos"),]
testing[which(testing$TARGET=="pos")[1:3],]
# sampling = "smote")
#
# svmGrid <-  expand.grid(size=seq(1, 5,1),
#                         decay=seq(0.1,1,0.1))
mod0 <- train(TARGET ~ ., data = training,
method = "nnet",
# tuneGrid = svmGrid,
trControl = fitControl)
mod1 <- train(TARGET ~ ., data = training,
method = "svmLinear",
trControl = fitControl)
mod2 <- train(TARGET ~ ., data = training,
method = "svmRadial",
trControl = fitControl)
mod3 <- train(TARGET ~ ., data = training,
# metric = "Sens",
# maximize = TRUE,
method = "glm",
trControl = fitControl)
mod4 <- train(TARGET ~ ., data = training,
method = "bayesglm",
trControl = fitControl)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4))
# bwplot(compare,metric="Accuracy")
summary(compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
# bwplot(compare,metric="Accuracy")
summary(compare)
splom(compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
predictions <- predict(mod0, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
table(testing$TARGET)
# sampling = "smote")
#
# svmGrid <-  expand.grid(size=seq(1, 5,1),
#                         decay=seq(0.1,1,0.1))
mod0 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "nnet",
# tuneGrid = svmGrid,
trControl = fitControl)
mod1 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "svmLinear",
trControl = fitControl)
mod2 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "svmRadial",
trControl = fitControl)
mod3 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "glm",
trControl = fitControl)
mod4 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "bayesglm",
trControl = fitControl)
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4))
# bwplot(compare,metric="Accuracy")
summary(compare)
splom(compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(compare, scales=scales)
predictions <- predict(mod0, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
predictions <- predict(mod1, testing)
confusionMatrix(predictions, testing$TARGET,mode = "everything",positive = "pos")
predictions <- predict(mod2, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
predictions <- predict(mod3, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
predictions <- predict(mod0, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
predictions <- predict(mod3, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
predictions <- predict(mod4, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
compare <- resamples(list(NN=mod0,
SVM.Linear=mod1,
SVM.Radial=mod2,
LogReg=mod3,
BayesLogReg=mod4))
mod5 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "rf",
trControl = fitControl)
predictions <- predict(mod5, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
mod3 <- train(TARGET ~ ., data = training,
metric = "Sens",
maximize = TRUE,
method = "glm",
trControl = fitControl)
predictions <- predict(mod3, testing)
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
predictions <- predict(mod3, testing,type = "prob")
confusionMatrix(predictions, testing$TARGET,mode = "sens_spec",positive = "pos")
predictions
varImp(mod3)
varImp(mod0)
plot(varImp(mod0))
head(predict(dummies, newdata = df_meta_pp))
#one-hot encoding
dummies <- dummyVars(~.,data = df_meta_pp,fullRank = T)
head(predict(dummies, newdata = df_meta_pp))
plot(varImp(mod1))
featurePlot(training, training$TARGET)
featurePlot(training)
